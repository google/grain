{
  "cells": [
    {
      "metadata": {},
      "id": "7696e57f",
      "cell_type": "markdown",
      "source": [
        "# Reading Bagz Files\n",
        "\n",
        "This tutorial gives an overview of integrating [Bagz](https://github.com/google-deepmind/bagz/) file format into Grain pipeline. Bagz, an alternative to ArrayRecord, is a novel file format which supports per-record compression and fast index-based lookup. It can also integrate with Apache Beam, a feature that we're going to present in this tutorial first.\n",
        "\n",
        "## Setup\n",
        "\n",
        "To start we need to make sure we have all required packages. We pin JAX's version as the latest Apache Beam doesn't support NumPy 2.0 yet."
      ]
    },
    {
      "metadata": {},
      "id": "80a0bf59",
      "cell_type": "code",
      "source": [
        "%pip install grain bagz apache-beam jax==0.4.38"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "id": "aa58f4f2",
      "cell_type": "code",
      "source": [
        "import grain\n",
        "import bagz\n",
        "from bagz.beam import bagzio\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import random\n",
        "import apache_beam as beam"
      ],
      "outputs": [],
      "execution_count": 2
    },
    {
      "metadata": {},
      "id": "34fe0fda",
      "cell_type": "code",
      "source": [
        "assert np.__version__[0] == \"1\", \"Apache Beam requires NumPy\u003c2\""
      ],
      "outputs": [],
      "execution_count": 3
    },
    {
      "metadata": {},
      "id": "b6e6ceca",
      "cell_type": "markdown",
      "source": [
        "## Apache Beam\n",
        "\n",
        "Likewise ArrayRecord, Bagz package can also integrate with the Apache Beam library to build ETL pipelines. In the example below we construct a pipeline which consumes some in-memory list, performs simple transformations, and loads outputs to a Bagz file with a `bagzio` module. `@*` in the filename indicates that we will have an unspecified number of shards this pipeline. To learn more about sharding in Bagz, please see [Bagz docs](https://github.com/google-deepmind/bagz/tree/main?tab=readme-ov-file#sharding)."
      ]
    },
    {
      "metadata": {},
      "id": "6e6221fd",
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  data = [\"record1\", \"record2\", \"record3\"]\n",
        "  _ = (\n",
        "      pipeline\n",
        "      | 'CreateData' \u003e\u003e beam.Create(data)\n",
        "      | 'Capitalize' \u003e\u003e beam.Map(lambda x: x.upper())\n",
        "      | 'Encode' \u003e\u003e beam.Map(lambda x: x.encode())\n",
        "      | 'WriteData' \u003e\u003e bagzio.WriteToBagz('beam_data@*.bagz')\n",
        "  )"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 4
    },
    {
      "metadata": {},
      "id": "b35aefdf",
      "cell_type": "code",
      "source": [
        "file = pathlib.Path(\"beam_data-00000-of-00001.bagz\")\n",
        "reader = bagz.Reader(file)\n",
        "print(list(reader))"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[b'RECORD1', b'RECORD2', b'RECORD3']\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "metadata": {},
      "id": "241f3b31",
      "cell_type": "markdown",
      "source": [
        "## Creating and reading Bagz files\n",
        "\n",
        "As Bagz format is record-based we can use a simple loop and `bagz.Writer` context manager to write our contents to the output file."
      ]
    },
    {
      "metadata": {},
      "id": "ee2dc000",
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "records = list(f\"Record: {random.randint(100, 1000)}\" for _ in range(40))\n",
        "\n",
        "file = pathlib.Path(\"data.bagz\")\n",
        "\n",
        "with bagz.Writer(file) as writer:\n",
        "    for rec in records:\n",
        "        writer.write(rec)"
      ],
      "outputs": [],
      "execution_count": 6
    },
    {
      "metadata": {},
      "id": "53a84846",
      "cell_type": "markdown",
      "source": [
        "Bagz supports random access, therefore we can lookup items by index, check length of the file, and slice it arbitrarily."
      ]
    },
    {
      "metadata": {},
      "id": "ac1811d4",
      "cell_type": "code",
      "source": [
        "reader = bagz.Reader(file)\n",
        "\n",
        "print(len(reader))\n",
        "\n",
        "print(reader[10])\n",
        "\n",
        "print(list(reader[5:15]))"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40\n",
            "b'Record: 792'\n",
            "[b'Record: 350', b'Record: 328', b'Record: 242', b'Record: 854', b'Record: 204', b'Record: 792', b'Record: 858', b'Record: 658', b'Record: 189', b'Record: 704']\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "metadata": {},
      "id": "47c50d08",
      "cell_type": "markdown",
      "source": [
        "## Grain pipeline with Bagz files\n",
        "\n",
        "With random access in mind, we can now consume Bagz files in a Grain pipeline with `grain.MapDataset` class. Then applying any transformation is the same as with other sources, such as ArrayRecord files."
      ]
    },
    {
      "metadata": {},
      "id": "94496e71",
      "cell_type": "code",
      "source": [
        "dataset = (\n",
        "    grain.MapDataset.source(reader)\n",
        "    .shuffle(seed=42)\n",
        "    .map(lambda x: x.decode())  # move from bytes to strings\n",
        "    .filter(lambda x: x[-1] != \"6\")  # let's filter out some files\n",
        "    .map(lambda x: x.upper())  # and capitalize them\n",
        "    .to_iter_dataset()\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 8
    },
    {
      "metadata": {},
      "id": "0002bb2c",
      "cell_type": "code",
      "source": [
        "print(f\"Filtered out: {len(reader) - len(list(dataset))} records.\")\n",
        "\n",
        "list(dataset)"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered out: 2 records.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['RECORD: 704',\n",
              " 'RECORD: 674',\n",
              " 'RECORD: 877',\n",
              " 'RECORD: 189',\n",
              " 'RECORD: 325',\n",
              " 'RECORD: 323',\n",
              " 'RECORD: 303',\n",
              " 'RECORD: 125',\n",
              " 'RECORD: 381',\n",
              " 'RECORD: 990',\n",
              " 'RECORD: 127',\n",
              " 'RECORD: 859',\n",
              " 'RECORD: 858',\n",
              " 'RECORD: 204',\n",
              " 'RECORD: 854',\n",
              " 'RECORD: 350',\n",
              " 'RECORD: 132',\n",
              " 'RECORD: 338',\n",
              " 'RECORD: 928',\n",
              " 'RECORD: 532',\n",
              " 'RECORD: 328',\n",
              " 'RECORD: 818',\n",
              " 'RECORD: 833',\n",
              " 'RECORD: 658',\n",
              " 'RECORD: 195',\n",
              " 'RECORD: 214',\n",
              " 'RECORD: 529',\n",
              " 'RECORD: 765',\n",
              " 'RECORD: 617',\n",
              " 'RECORD: 384',\n",
              " 'RECORD: 658',\n",
              " 'RECORD: 559',\n",
              " 'RECORD: 703',\n",
              " 'RECORD: 925',\n",
              " 'RECORD: 130',\n",
              " 'RECORD: 792',\n",
              " 'RECORD: 242',\n",
              " 'RECORD: 754']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 9
    }
  ],
  "metadata": {
    "jupytext": {
      "default_lexer": "ipython3",
      "formats": "ipynb,md:myst"
    },
    "kernelspec": {
      "display_name": "grain-dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
